---
title: "[컴퓨터네트워크] 3장. 트랜스포트 계층 2"
date: 2020-09-02T15:34:30-04:00
classes: wide
categories:
  - Computer Network
tags:
  - Computer Network
  - CS
---

**Warning Notice:** 이 글은 **COMPUTER NETWORKING A TOP DOWN APPROACH - James F. Kurose, Keith W. Ross(Pearson)** 도서를 읽고 개인적인 학습을 위해서 정리한 내용입니다. 틀린 내용이 있을 수 있습니다.
{: .notice--warning}

## 3.5 연결지향형 트랜스포트 : TCP

### 3.5.1 TCP 연결

이제 앞서 공부했던 신뢰적 데이터 전송원리를 적용하여 개발한 트랜스포트 프로토콜 TCP에 대해서 먼저 간략히 소개해보자.

- **Point to Point 통신** : TCP 연결을 통해서 통신을 하면 반드시 TCP로 연결된 하나의 네트워크 프로세스와 하나의 네트워크 프로세스 간의 통신만이 가능하다.
- **연결 지향형 프로토콜(Connection-Oriented protocol)** : 네트워크 상의 두 프로세스가 TCP 방식으로 통신하기 위해서는 미리 두 프로세스간의 연결(Connection)이 형성되어야 한다. TCP Connection을 생성하기 위해서는 three-way handshake라는 방식이 사용된다.
- **신뢰적인 바이트 스트림 단위 전송** : TCP에서는 애플리케이션에서 전송하는 데이터를 경계가 없는 바이트 스트림으로 간주한다. 신뢰적이라고 함은 TCP를 통해서 통신하는 네트워크 애플리케이션은 송수신 하는 데이터 바이트 스트림이 손실 및 손상이 없고 항상 올바른 순서가 유지됨을 보장받는다는 의미이다.
- **MSS(Maximum Segment Size)** : 세그먼트의 애플리케이션 메시지에 할당할 수 있는 최대 크기
- **full duplex** 통신 : 하나의 TCP Connection을 통해서 송신과 수신이 동시에 이루어질 수 있다.
- **flow controlled** : 수신자가 받을 수 있는 속도 이상으로 데이터를 전송하지 않도록 조절할 수 있다.
- **pipelined**

### 3.5.3 TCP 세그먼트 구조

![30](https://user-images.githubusercontent.com/31771548/91964425-1726c100-ed4a-11ea-9403-22ec74968963.png)

TCP 세그먼트의 헤더는 보통의 경우 20바이트로 구성되어 있다. TCP 헤더의 크기 정보는 head len이라는 필드에 32bit 워드 단위로 기록된다. 다음은 TCP 세그먼트의 주요한 필드들에 대한 설명이다.

- **16bit source port #, dest port #** : Multiplexing과 Demultiplexing을 위한 필드
- **32bit sequence number** : pipe line된 여러개의 세그먼트를 전송할 경우, 세그먼트를 구분하는 순서번호. 순서번호는 데이터 스트림의 바이트마다 부여되며 세그먼트에 대한 순서번호는 그 세그먼트가 가지고 있는 데이터 바이트 중 첫번째 바이트의 순서번호를 의미한다.
- **32bit acknowledgement number** : pipe line된 여러개의 세그먼트를 수신할 경우, 특정 세그먼트를 수신했다는 것을 구분하기 위한 확인 응답 번호. n번호의 세그먼트를 정상 수신한 경우 n+1번의 acknowledgement number를 송신자 측에 전송한다.
- **4bit head len** : TCP 세그먼트 헤더 크기를 32bit 워드 단위로 나타낸것
- **6bit not used**
- **UAPRSF**
  - U : Urgent data를 의미함. 실제로는 사용되지 않음
  - A : aknowledgement number가 유효함을 나타내는 필드
  - P : PSH. 수신자가 곧바로 수신한 데이터를 상위 계층에 전송해야함을 의미. 실제로는 사용하지 않는다.
  - R, S, F: TCP 연결 및 해제 신호 전송시 사용하는 필드
- **receive window** : 수신자의 수신 버퍼 크기를 체크하여 송신속도를 조절하는 flow control 시에 사용하는 필드
- **checksum** : 세그먼트에 손상이 있는지 없는지 체크하는 필드
- Urg Data pointer : 잘 사용하지 않음
- Options : TCP에 대한 서비스 옵션들을 설정하는 필드.

#### 순서번호와 확인 응답 번호

TCP에서 순서번호는 세그먼트 단위로 부여되는 것이 아니라 전송되는 데이터 스트림의 바이트 단위로 부여된다.

TCP에서는 전송하고자 하는 데이터 스트림을 MSS 사이즈로 나누어서 세그먼트들을 생성한다. 이 때 세그먼트의 **sequence number** 필드에 들어가는 순서번호는 **해당 세그먼트가 표함하고 있는 데이터 바이트들 중 가장 앞쪽 바이트의 순서번호**를 의미한다.

수신자쪽에서는 송신자쪽에서 보내온 데이터 바이트들을 정상적으로 수신하고 마지막 **수신한 바이트의 순서번호 + 1로 acknowledgement number를 설정**한다. 이는 **ack num - 1 까지의 바이트들을 모두 정상 수신하고, 다음으로 ack num에 대한 바이트를 수신하기를 기대한다는 의미**이다. acknowledgement number는 **culmulative ack**으로 동작한다. 즉 수신자가 ack num으로 n을 전송한다면, **n 이전 데이터들에 대해서 모두 정상 수신함을 의미**한다.

![31](https://user-images.githubusercontent.com/31771548/91964428-1857ee00-ed4a-11ea-9546-be64aa394be1.png)

#### Telnet 프로토콜에서의 예시

![32](https://user-images.githubusercontent.com/31771548/91964432-18f08480-ed4a-11ea-809a-0b41da8f6b54.png)

Telnet은 원격 로그인을 위한 애플리케이션 프로토콜이다. TCP를 트랜스포트 프토토콜로 이용한다. 특이한점은 데이터를 송수신할 때 1바이트 크기로만 송수신한다는 것이다.

위 그림은 HostA에서 HostB 컴퓨터를 원격으로 로그인하는 시나리오를 보여준다. Host A에서 문자 C를 입력하면 HostB에서는 해당 문자가 입력되었음을 Host A의 모니터에서 확인할 수 있도록 문자 C를 다시 보낸다(echo). 주목할 점은 HostB에서 문자 C를 돌려 보낼때, 이전에 받은 문자 C에 대한 Acknowledgement number를 같이 전송한다는 것이다. 이렇게 서버와 클라이언트간 확인 응답이 데이터 세그먼트를 전송하는 과정에서 함께 전달될 수 있다. 이러한 확인 응답은 데이터 세그먼트 상에서 **피기백(piggy back)** 되었다고 한다.

### 3.5.3 왕복시간(RTT) 예측과 타임아웃

TCP에서 데이터 송수신간 세그먼트 손실이 일어나면 송신자는 해당 세그먼트를 재전송한다. 이러한 동작이 가능한 이유는 송신자에서 세그먼트에 대한 타이머를 관리하기 때문이다. 타이머의 타임아웃 시간은 premature timeout이 일어나지 않도록 수신자로부터 ack 세그먼트가 도달하기를 기다릴만큼은 길어야 하나, 손실된 세그먼트에 대한 반응이 즉각적으로 일어날만큼은 짧아야 한다. 그럼 이러한 타임아웃시간은 어떻게 정해야할까?

먼저 생각할 수 있는 것은 세그먼트에 대한 RTT보다는 타임아웃이 길어야 한다는 것이다. 적절한 타임아웃을 정하기 위해서 TCP에서는 세그먼트를 보낼때 해당 세그먼트에 대한 ack이 도달할때까지 걸리는 시간인 **sampleRTT**를 측정한다. 여러 세그먼트를 파이프라인하여 보낼때는 하나의 세그먼트에 대해서만 측정하며, 재전송 세그먼트에 대해서는 측정하지 않는다. 이러한 sampleRTT는 네트워크 사정에 따라서 변동이 존재한다. 이러한 sampleRTT를 타임아웃 계산에 그대로 사용하기보다는 전체 sampleRTT에 대한 평균적인 값인 **EstimatedRTT** 값을 사용한다. EstimatedRTT는 다음과 같이 계산될 수 있다.

![rtt_cal](https://user-images.githubusercontent.com/31771548/91965724-de87e700-ed4b-11ea-9b1d-8344cf8ec203.png)

위 계산 방식은 프로그래밍 계산 방식으로 표현한 것이다. 즉 우변의 EstimatedRTT는 이전에 계산한 값이고, 좌변의 EstimatedRTT는 현재의 sampleRTT 값을 가지고 새로 계산한 EstimatedRTT 값이다. 여기서 &alpha; 값은 보통 **0.125** 값을 사용한다.

위 계산식에서 알 수 있듯이 Timeout 계산에 사용하는 RTT 값은 현재의 sampleRTT 값과 더불어서 과거의 sampleRTT 까지 고려하는 방식이다. 계산을 거듭할수록 과거의 sampleRTT들의 EstimatedRTT에 대한 영향력이 지수적으로 떨어지고, 상대적으로 현재의 sampleRTT의 EstimatedRTT에 대한 영향력이 크게 작용한다. + 초기 EstimatedRTT 값은 첫 SampleRTT 값과 같게 설정한다고 한다.

![33](https://user-images.githubusercontent.com/31771548/91964433-18f08480-ed4a-11ea-9e7a-95b950be1595.png)

그러나 여전히 EstimatedRTT 만으로는 타임아웃을 계산하기에는 부족하다. 위 그림에서 알 수 있듯이 세그먼트에 대한 RTT 값은 종종 EstimatedRTT를 뛰어넘게 되어 premature timeout을 일으키게 한다. 이런 sampleRTT에 대한 변동률을 예측하기 위해서 **DevRTT** 값을 사용한다. DevRTT값은 다음과 같이 계산한다.

![rtt_dev](https://user-images.githubusercontent.com/31771548/91966034-4d654000-ed4c-11ea-9164-2f1ace7f536e.png)

이 값은 EstimatedRTT에 대한 sampleRTT의 평균 편차 정도의 의미를 가지고 있다. &beta; 값은 주로 **0.25** 값을 사용한다. 이제 EstimatedRTT와 DevRTT 값을 가지고 타이머의 타임아웃값인 TimeoutInterval을 다음과 같이 계산할 수 있다.

![34](https://user-images.githubusercontent.com/31771548/91964436-19891b00-ed4a-11ea-9e48-2f6b70d133d4.png)

초기 TimeoutInterval의 값은 1초로 설정되기를 권장한다. 또한 재전송이 발생하는 경우 TimeoutInterval은 앞선 TimeoutInterval의 2배를 사용한다. 그러나 세그먼트가 수신되고 EstimatedRTT값이 계산되면 TimeoutInterval 값은 다시 위 수식을 따른다.

### 3.5.4 신뢰적인 데이터 전달

TCP는 IP 채널 위에서 신뢰적 데이터 전달 서비스를 제공하게 된다. IP는 데이터의 손실, 손상을 일으킬 수 있고, 패킷이 순서대로 전달되지 않을 수 있는 서비스를 제공한다. 이러한 채널위에서 TCP는 신뢰적 데이터 전달 서비스를 제공하기 위해 앞 절에서 설명한 타이머, 재전송, checksum, 순서번호, 확인응답 번호, 누적 확인 응답, 파이프라인 기법 등을 사용한다.

TCP에서는 가장 오래된 확인응답을 받지 않은 세그먼트에 대해서만 단일 타이머를 관리한다. 또한 재전송하는 세그먼트 개수는 1개로 설정하는 등 3.4절에서 설명하는 rdt3.0과는 조금 다르게 동작한다.

또한 TCP의 송신자가 재전송을 하는 시나리오가 timeout 이외에 duplicate ack에 대한 fast retransmission이 하나 더 추가되는데 일단은 duplicate ack과 혼잡제어, 흐름제어 기능을 생각하지 않은 간단한 송신자 모델에 대해서 알아보자.

#### 간략화된 송신자 모델

![35](https://user-images.githubusercontent.com/31771548/91964438-19891b00-ed4a-11ea-99f2-382fceb99c1f.png)

송신자에게 일어날 수 있는 각 이벤트에 대한 송신자의 동작은 다음과 같다.

- 최초에 송신자의 SendBase와 NextSeqNum를 초기화 한다.
- 어플리케이션 계층으로부터 메시지를 전달받은 경우 : 세그먼트를 생성하고 Sequence number를 NextSeqNum으로 설정한다. 그 다음 하위 계층인 IP에 세그먼트를 전달한다. 후에 NextSeqNum에 전달할 데이터 바이트 길이를 더해 갱신한다. 현재 타이머가 동작하지 않는다면, 타이머를 시작한다.
- 수신자로부터 ACK 번호로 y가 설정된 세그먼트를 전달받은 경우 : y가 Sendbase보다 큰 경우 Sendbase를 y로 갱신한다. 여기서 Ack은 culmulative ack이다. 즉, 송신자가 보낸 y-1까지의 모든 바이트가 수신자에게 정상 전달되었다는 것이다. 아직 ACK을 받지 못한 세그먼트가 존재하면 타이머를 다시 시작시킨다. 아니라면 타이머를 멈춘다.
- 타임아웃 이벤트가 발생한 경우 : 타임아웃에 대한 세그먼트(가장 오래된 ACK 신호를 받지 못한 세그먼트)만 재전송한 뒤 타이머를 재시작한다.

#### 여러가지 재전송 시나리오

![36](https://user-images.githubusercontent.com/31771548/91964440-1a21b180-ed4a-11ea-81a5-104ea32899cc.png)

첫번째 시나리오는 수신자의 ack 신호가 손실되어 타임아웃이 일어나 재전송이 일어난 경우이다. 두번째는 송신자가 2개의 세그먼트를 전송하였는데, 첫번째 세그먼트에대한 ACK이 도착하기 전에 성급한 타임아웃이 일어난 경우이다. 송신자는 첫번째 세그먼트를 재전송한다. 이 후 두 개의 세그먼트에 대한 ACK 신호가 전달되어 송신자의 Sendbase를 갱신한다. 재전송한 세그먼트에 대해서 수신자는 마지막에 수신받은 세그먼트(두 번째 세그먼트)에 대한 ACK 신호를 재전송한다. 송신자는 두 번째에 대한 duplicate ACK 신호를 받게 되는데, 이 경우 확인응답번호(y)가 Sendbase보다 크지 않기 때문에 단순히 이 ACK 신호를 무시하게 된다.

<center><img src="https://user-images.githubusercontent.com/31771548/91964442-1aba4800-ed4a-11ea-94d3-ee6e830277b4.png"></center>

세번째 시나리오는 송신자가 2개의 세그먼트를 전송하고 수신자가 두 개 세그먼트 모두 정상수신하였는데, 두 개의 ACK 신호 중 첫번째가 손실된 경우이다. 이 경우 두 번째 세그먼트에 대한 ACK 신호만 송신자로 전송되는데, 이 ack 신호는 culmulative ack 이기 때문에 송신자는 수신자가 119번째 바이트까지 정상수신함을 확신하고, 다음에 데이터를 전송할 경우 120번째 바이트부터 세그먼트를 구성하여 전송하게 된다.

#### 수신자에서의 동작

![38](https://user-images.githubusercontent.com/31771548/91964444-1aba4800-ed4a-11ea-85f1-8cedc6fe3503.png)

위 도표는 수신자에서 발생할 수 있는 이벤트에 대한 수신자 동작을 나타낸다. 이전 절에서 설명한 rdt 3.0과는 다르게 동작하는 점이 몇가지 있다. 먼저 첫번째 행을 보자. 송신자가 여러개의 세그먼트를 파이프라인하여 동시에 보낼 경우, rdt3.0에서는 각 세그먼트에 대해서 ack신호를 보내주었다. 그러나 조금만 생각해보면 개선의 여지가 있다. 수신자가 보내는 **ack신호는 culmulative ack 이기 때문에 마지막에 수신한 세그먼트에 대한 ack 신호만 보내주면 송신자는 모든 세그먼트가 정상 송신되었다는 것을 확신할 수 있다**. 이렇게 TCP 수신자는 세그먼트를 수신할 때 바로 ack 신호를 전달하지 않고, 대략 500ms를 다음 세그먼트가 올때까지 기다려서 마지막 세그먼트에 대해서만 ack 신호를 보내준다. 이러한 ack을 **delayed ack**이라고 한다.

다음 4번째 행을 보기전에, 3번째 행에서 이어지는 상황이라 3번째 행의 경우를 먼저 설명하겠다. 3번째 행은 송신자가 여러 세그먼트를 보낼 때, 중간 세그먼트가 손실되거나, 세그먼트의 순서가 뒤바뀌어서 수신자에게 도착하는 경우이다. 수신자는 예상되는 순서번호보다 더 뒤의 세그먼트를 수신하게 되면 이에 대한 ack 신호를 보내지 않고, 수신자가 수신하기를 기대하는 세그먼트에 대한 순서번호를 확인응답번호에 담아서 재전송하게된다.

TCP에 대한 RFC 문서는 3번 상황과 같이 수신자가 예상되는 순서번호보다 더 뒤의 세그먼트를 수신하게 되는 상황에 대해서 TCP 구현자에게 그 동작에 대한 구현을 맡긴다. 따라서 TCP는 단순히 이 세그먼트를 버릴 수도 있고, 버퍼링할 수도 있다. 4번 상황은 수신자가 이 세그먼트를 버퍼링하는 상황을 설명한다. 수신자는 올바르게 수신한 세그먼트와 먼저 수신한 세그먼트 사이의 갭을 채워주는 세그먼트를 수신한 경우 곧바로 ack 신호를 전달한다. 이 때 확인응답번호는 올바르게 수신한 세그먼트와 앞선 번호의 세그먼트 사이 간격에서 가장 아래쪽 세그먼트의 순서번호이다. (이는 TCP가 파이프라인 기술로 GBN과 SR 기술을 함께 사용할 수 있음을 의미한다.)

#### 빠른 재전송(fast retransmission)

앞서 재전송을 위한 타임아웃 시간을 계산하는 방법에 대해서 살펴보았다. 그러나 때에 따라서 이러한 타임아웃 시간도 길게 느껴질때가 있다. 손실된 세그먼트에 대해서 재전송 응답이 늦어지는 상황은 결코 적절한 대처가 아니다. 그런데 파이프라인된 세그먼트를 여러개 보낼 경우 타임아웃을 기다리지 않고도 세그먼트 손실을 감지해낼 수가 있다. 다음 그림을 보자.

![40](https://user-images.githubusercontent.com/31771548/91964449-1beb7500-ed4a-11ea-95c6-5f18ada6a161.png)

송신자는 총 5개의 세그먼트를 파이프라인하여 수신자에게 전송한다. 이 때 2번재 세그먼트가 중간에 손실되었다. 수신자는 첫번째 세그먼트를 수신한 뒤에 Ack 100을 전송하고, 순서가 맞지않은 나머지 3개의 세그먼트를 전송받은 경우에도 Ack100을 보내게 된다. 송신자는 Ack100을 받은 뒤, Ack 120을 받기를 기대하지만 duplicate Ack 100 이 3번 돌아온다. 두 번째 세그먼트가 정상 송신 되었다면 이렇게 이전에 전송한 세그먼트에 대해서 같은 ack이 3번이다 재전송되는 일은 없었을 것이다. 따라서 송신자는 두번째 세그먼트 손실을 감지하게 되고, 타임아웃을 기다리기전에 바로 두번째 세그먼트를 재전송하게 된다. 이와 같은 기술을 **Fast Retransmission**이라고 한다.

### 3.5.5 흐름제어

![41](https://user-images.githubusercontent.com/31771548/91964450-1beb7500-ed4a-11ea-978f-e7ee099ba048.png)

각 end system에서는 각 TCP 소켓에 대한 버퍼를 관리한다. 송신자 TCP에서 세그먼트를 전송하면 이 버퍼에 일단 저장되고, 이 후 수신자 측 상위 애플리케이션이 이 버퍼에서 데이터를 읽을 수 있다. 애플리케이션이 버퍼에서 데이터를 읽는 시간과 소켓 버퍼에 세그먼트가 도착하는 시간은 일치하지 않을 수 있으며, 보통 애플리케이션이 데이터를 읽는 속도가 더 느리다. **송신자가 세그먼트를 계속해서 전송한다면 자연스럽게 버퍼에 데이터가 계속 쌓이게 되고 오버플로우가 발생할 수 있다.**

TCP에서는 이러한 오버플로우가 발생하지 않도록 컨트롤하는 **흐름제어(flow control)** 기법을 활용하고 있다. **흐름제어란 수신자가 데이터를 받아들이는 속도보다 송신자의 데이터 전송속도가 더 빠르지 않도록하는 것을 의미한다.** 이러한 흐름제어는 어떻게 구현될까?

![42](https://user-images.githubusercontent.com/31771548/91964453-1c840b80-ed4a-11ea-8b1c-ebea29ac19e2.png)

먼저 간략하게 설명하자면 송신자는 **수신자 소켓의 버퍼에서 비어있는 버퍼의 크기를 수신윈도우(Receive Window)라는 변수로 관리**하여 송신속도를 조절한다. 이 수신 윈도우의 크기는 수신자가 송신자에게 세그먼트를 보낼 때, 세그먼트의 수신윈도우 헤더필드에 기록되어 보내진다.

수신자 호스트의 TCP 소켓에는 버퍼가 존재한다고 하였다. 이 수신버퍼의 크기를 TCP는 이 버퍼 상태에 대한 몇가지 변수로 관리하게 된다. 먼저 수신자 TCP 소켓의 버퍼 크기를 **RcvBuffer** 라고 하자. 그리고 송신자로부터 전송받은 데이터 스트림의 마지막 바이트 번호를 **LastByteRcvd**, 수신자에 소켓 버퍼에서 읽어들인 데이터 스트림의 마지막 바이트 번호를 **LastByteRead** 라고 해보자. 이 때 소켓 버퍼의 오버플로우가 허용되지 않으므로 다음과 같이 수식이 성립된다.

![buffer1](https://user-images.githubusercontent.com/31771548/91968004-fb71e980-ed4e-11ea-8618-33ef47d113df.PNG)

이때 수신자 소켓에서 비어있는 버퍼의 크기는 다음과 같다

![buffer2](https://user-images.githubusercontent.com/31771548/91968006-fc0a8000-ed4e-11ea-850e-3e50396fb69f.PNG)

이제 이 값은 수신자가 송신자로부터 추가적으로 전송받을 수 있는 여유 공간값인 수신윈도우 **rwnd** 로 설정된다. 수신자는 이 값을 송신자에게 보내는 세그먼트의 수신 윈도우 헤더 필드에 설정한 뒤 송신자에게 보낸다.

이 값을 가지고 송신자는 데이터 전송속도를 조절하기 위해 역시 몇가지 변수값을 관리한다. **LastByteSent** 는 송신자가 수신자에게 보낸 데이터 스트림 중 마지막 바이트 번호, **LastByteAcked** 는 수신자로부터 ack 신호를 받은 데이터 스트림 중 마지막 바이트 번호이다. 송신자가 흐름제어를 위해서는 다음과 같은 수식을 보장하도록 한다.

![buffer3](https://user-images.githubusercontent.com/31771548/91968010-fca31680-ed4e-11ea-8c10-b6e0b8dc9863.PNG)

### 3.5.6 TCP 연결 관리

TCP는 송신자와 수신자가 서로 통신을 하기 전에 미리 연결을 설정하는 연결지향형 프로토콜이라고 하였다. 송신자와 수신자가 연결을 설정하기 위해서는 특별한 3개의 세그먼트를 주고받는데 이러한 과정을 **three-way handshaking** 이라고 한다. 이 연결과정에 대해서 알아보자.

![43](https://user-images.githubusercontent.com/31771548/91964456-1c840b80-ed4a-11ea-98ab-664d51cab5b1.png)

네트워크에 연결된 두 A, B end system 위에서 돌아가는 A, B 프로세스가 있다. A 프로세스는 B 프로세스와 통신하기 위해서 B 프로세스에게 연결에 대한 초기화를 요청한다. 이 때 연결에 대한 초기화를 진행하는 프로세스(A)를 클라이언트 프로세스, B 프로세스를 서버 프로세스라고 한다.
클라이언트 프로세스는 클라이언트 TCP에게 B 프로세스에 대한 연결요청 작업을 요청한다. 클라이언트 TCP는 먼저 데이터 페이로드가 비어있는 세그먼트를 생성한다. **초기 sequence number는 임의로 지정**한다. 여기서는 x라고 해보자. 또한 세그먼트의 **SIN 헤더필드 플래그를 1로 셋팅** 한뒤 IP를 통해 호스트 B에게 전달한다. 셋팅된 SIN 플래그는 해당 세그먼트가 TCP 연결을 요청하는 세그먼트라는 것을 나타낸다. 이러한 세그먼트를 종종 **SIN 세그먼트** 라고도 한다.

호스트 B는 IP로 부터 세그먼트를 추출하고, SIN 플래그가 설정되어있는 것을 확인한다. (만약 목적지 포트번호에 대응하는 서버 소켓이 있다면) 서버 TCP는 SIN 세그먼트에 대한 응답 세그먼트를 생성한다. 이 세그먼트에 3가지 주요 헤더 필드를 설정한다. 첫번째는 서버 TCP가 임의로 생성한 초기 **sequence number(y)**이다. 두번째는 SIN 세그먼트에 대한 확인 **응답번호 ack(x + 1)** 이다. 마지막으로 **SIN 플래그 역시 1로 세팅**한다. 이는 서버 TCP 역시 클라이언트 TCP에게 연결에 대한 요청을 하는 것이라고 이해할 수 있다. 클라이언트 TCP의 연결 요청에 대한 응답(ack)과 서버 TCP의 연결 요청을 하나의 세그먼트에 설정하기 때문에 이 세그먼트를 **SINACK 세그먼트** 라고도 한다.

다시 클라이언트 TCP는 수신자의 **SINACK**을 받는다. 일단 이 **SINACK** 세그먼트에 대한 확인 응답 ack 을 보내기 위해서 세그먼트를 생성하여 **확인 응답번호 (y + 1)를 설정**한다. 또한 서버가 연결 요청을 승인하였기 때문에 세그먼트의 페이로드에 애플리케이션 데이터를 추가할 수 있다. 다시 이 ACK 세그먼트를 수신자에게 전송한다.

그렇다면 왜 three-way handshaking을 사용하는 것일까? two-way handshaking을 사용하면 안되는 것인가? 다음은 two-way handshaking의 두 가지 실패사례를 설명하는 그림이다.

![44](https://user-images.githubusercontent.com/31771548/91964457-1d1ca200-ed4a-11ea-8aa7-2c3b68ebee4c.png)

첫번째 시나리오는 클라이언트가 서버로 연결요청을 한다. 이때 네트워크의 지연으로 서버쪽에서 확인응답이 늦어져서 타임아웃이 발생한다. 클라이언트는 다시 두번째 연결 요청을 보낸다. 그 사이 서버는 첫번째 연결 요청을 수신하고 연결을 생성한 다음 클라이언트에게 첫번째 연결 요청에 대한 확인 응답을 한다. 이 확인 응답을 받은 클라이언트는 최종 연결을 생성하게 된다. 이 연결을 모두 사용하고 나서 빨간 파선의 시점에서 연결이 끝나고 클라이언트 애플이케이션은 종료된다. 그런데 후에 클라이언트가 전송한 두번째 연결요청이 서버로 전송되는 상황이 발생한다. 서버는 이에 대한 응답을 클라이언트에게 보내지만 클라이언트 애플이케이션은 이미 종료된 상황이므로 서버에만 연결이 생성되어 있는 반쪽짜리 connection 생성된다.

두번째에서는 상황이 더 악화된다. 빨간 파선 이 전에 클라이언트가 재전송한 특정 세그먼트가 서버에 있는 반쪽짜리 connection에 들어가게 된다.

two-way handshaking의 경우 서버 TCP는 클라이언트 TCP로 부터 연결 요청이 오는 경우, 자신도 클라이언트에게 연결 요청을 보내는 것이 아니라 바로 연결을 생성하게 된다. 이러한 점이 여러 오류를 일으킬 수 있는 원인이 된다.

다음은 서버와 클라이언트의 TCP 연결 생성과정을 함께 표현한 FSM이다.

![45](https://user-images.githubusercontent.com/31771548/91964459-1db53880-ed4a-11ea-8243-e6fc995c94fa.png)

#### TCP connection closing

TCP 연결을 생성한 뒤, 연결을 종료하는 과정은 4개의 세그먼트 송수신으로 이루어진다.

![46](https://user-images.githubusercontent.com/31771548/91964460-1db53880-ed4a-11ea-82cf-7283f1860462.png)

먼저 연결을 끊기를 원하는 호스트가 연결 종료에 대한 세그먼트를 전송한다(여기서는 클라이언트가 먼저 연결 종료를 요청한다). 전송하는 세그먼트에 FIN 헤더필드 플래그를 1로 설정한다. 이는 해당 세그먼트가 연결 종료 요청에 대한 세그먼트라는 것을 의미한다. 수신자는 해당 세그먼트를 수신하고 FIN 헤더 필드가 설정되어 있음을 확인한다. 그 다음 이에 대한 ACK 신호를 보내게 된다. 아직 서버쪽은 연결을 유지하여 데이터를 전송할 수 있는 상태이다.

서버가 보내야하는 모든 세그먼트를 전송하고 난 뒤에 서버 TCP 역시 연결 종료에 대한 세그먼트를 세팅된 FIN 헤더 필드와 함께 전송한다. 송신자는 이 세그먼트를 수신하고 나서 이에 대한 ACK 세그먼트를 전송한다. 이 ACK 세그먼트를 다시 수신한 수신자는 곧바로 연결을 종료한다. 그러나 송신자는 ACK 세그먼트를 전송한 뒤 2 * maximum segment lifetime을 기다린 뒤에 연결을 종료한다. 왜냐하면 네트워크에 아직 송신자로 전달되지 못한 세그먼트가 남아있을 수 있기 때문이다. 이 일정 시간을 기다린 뒤에 마지막으로 송신자 역시 연결을 해제하게 된다.

## 3.6 혼잡제어의 원리

네트워크에 연결된 여러 end system에서 세그먼트를 계속해서 전송하면, 네트워크 중간의 라우터에서 패킷이 지연되거나, 손실되는 등의 혼잡이 발생할 수 있다. 앞서 TCP에서는 신뢰적 데이터 전송을 위해 손실된 세그먼트에 대해서 재전송하는 것을 배웠다. 그러나 이는 네트워크 혼잡의 증상은 해결할지 몰라도, 네트워크 혼잡의 근본 원인을 해결해주지는 못한다. 네트워크 혼잡 원인을 제거하려면 네트워크 상황에 따라서 end system TCP의 동작을 제어할 필요가 있다. 이러한 제어 기술을 알아보기 전에 네트워크에서 발생할 수 있는 혼잡에 대해서 간단한 환경에서부터 보다 복잡한 상황으로 조건을 추가하면서 혼잡의 원인과 비용에 대해서 알아보자.

### 3.6.1 혼잡의 원인과 비용

#### 시나리오 1 : 두 개의 송신자와 무한 버퍼를 가지는 하나의 라우터

![47](https://user-images.githubusercontent.com/31771548/91964462-1e4dcf00-ed4a-11ea-8e8b-61f3ec26ed30.png)

첫번째 시나리오는 두 개의 송신자가 각각의 수신자에게 데이터를 전송할 때 하나의 라우터를 공유하는 단일 홉 네트워크에 대한 이야기이다. 이 라우터에는 무한대의 크기를 가지는 버퍼가 있고, 링크 용량은 R이다. 또한 이 네트워크에서는 패킷 손실이 일어나지 않는다는 이상적인 가정을 한다. 송신자의 애플리케이션에서 트랜스포트 계층으로 전달하는 데이터의 전송률은 &lambda;<sub>in</sub> (바이트/초) 이다. 그리고 각 수신자가 송신자로부터 데이터를 전달받는 속도(연결당 처리량)를 &lambda;<sub>out</sub>이라고 해보자.

첫번째 그래프를 보자. 각 송신자의 &lambda;<sub>in</sub>가 작은 값일 경우에는 &lambda;<sub>in</sub> 값이 증가함에 따라서 &lambda;<sub>out</sub>값도 증가하게 된다. 그러나 두 송신자가 고정된 링크 용량을 가지는 하나의 라우터를 공유하기 때문에 각 송신자의 &lambda;<sub>in</sub> 값이 R/2를 넘어가게 되면 &lambda;<sub>out</sub>값은 R/2에서 더이상 증가하지 않게된다.

또한 라우터가 처리할 수 있는 용량 이상의 데이터가 전송되는 경우 해당 패킷들은 라우터의 버퍼에 저장되어 큐잉 지연을 발생시킨다. 1장에서 언급했듯이, 라우터가 처리할 수 있는 용량에 근접하게 송신자가 패킷을 전송할 수록 큐잉 지연은 두번째 그래프에서 볼 수 있듯이 무한대에 가깝게 증가하게 된다.

이렇게 이상적인 시나리오에서도 네트워크 혼잡은 비용을 발생시킨다. 즉, **패킷 도착률이 링크 용량에 가까워질수록 큐잉 지연은 커진다.**

#### 시나리오 2 : 두 개의 송신자와 유한버퍼를 가지는 하나의 라우터

![48](https://user-images.githubusercontent.com/31771548/91964463-1e4dcf00-ed4a-11ea-8a03-554bb25fc5f2.png)

이번에는 앞선 시나리오에서 좀더 현실적으로 라우터가 유한크기의 버퍼를 갖는다고 가정하자. 또한 네트워크에서 패킷 손실이 일어날 수 있어 송신자가 재전송을 하는 상황도 발생한다. 이 때 애플리케이션에서 트랜스포트 계층으로 전달하는 데이터 전송률을 &lambda;<sub>in</sub>이라고 표현한다. 이에 더해서 트랜스포트 계층에서 애플리케이션이 보내온 데이터와 함께 재전송할 데이터를 포함해서 네트워크에 전달하는 데이터 전송률을 &lambda;'<sub>in</sub>라고 표현해보자. (&lambda;'<sub>in</sub> >= &lambda;<sub>in</sub>)

시나리오 2에서도 여러 조건들을 추가해보면서 생각해보자. **첫번째는 송신자가 라우터 버퍼의 여유공간을 (신기하게도) 미리 알아서 버퍼 오버플로우가 발생하지 않도록 데이터를 전송한다고 해보자.**

![49](https://user-images.githubusercontent.com/31771548/91964465-1ee66580-ed4a-11ea-9771-270bed7ef98a.png)

이 경우 패킷손실은 발생하지 않을 것이며, 수신자의 연결당 처리량 &lambda;<sub>out</sub>은 &lambda;<sub>in</sub>이 증가함에 따라서 정비례하여 증가할 것이다. (재전송이 없기 때문에 &lambda;'<sub>in</sub> == &lambda;<sub>in</sub>)

**두 번째는 송신자가 라우터의 버퍼 사정을 알지 못하고 패킷을 전송하는 경우이다. 이 경우 패킷 손실이 발생할 수 있다. (이번에도 신기하게도) 송신자는 패킷 손실을 정확히 감지하여 손실된 패킷에 대해서만 재전송을 한다고 해보자.**

![50](https://user-images.githubusercontent.com/31771548/91964467-1f7efc00-ed4a-11ea-9d78-800c4df31b97.png)

이 경우  &lambda;'<sub>in</sub>는 애플리케이션에서 보내온 데이터와 재전송 데이터를 합한 결과로 계산된다. 이때 수신자의 연결당 처리량 &lambda;<sub>out</sub> 은 &lambda;'<sub>in</sub>값에 따라서 정비례하지 않고 약간 떨어지게 나타난다. 이는 송신자가 보내는 데이터에 재전송 데이터가 섞여있기 때문이다. 혼잡 네트워크는 **송신자가 버퍼 오버플로우 때문에 발생하는 손실에 따라서 재전송을 수행해야 한다는 비용을 낳는다.**

**세번째 경우는 패킷이 네트워크에서 전송되는 과정에서 지연이 발생하여 송신자의 타이머가 타임아웃 되는 것이다. 이 경우 송신자는 패킷을 중복해서 재전송 한다.**

![51](https://user-images.githubusercontent.com/31771548/91964471-20179280-ed4a-11ea-89a3-bd4063711a41.png)

중복되어 보내진 데이터는 네트워크를 혼잡하게 만들뿐만 아니라 이 같은 데이터를 보내는것은 라우터의 용량을 **허비** 하는 것이다. 왜냐하면 이 중복 패킷은 수신자에서 단순히 버려지기 때문이다. 이에 따라서 세번째 상황의 연결당 처리량 그래프는 앞선 상황보다 더 휘어진 곡선을 나타낸다. 혼잡 네트워크는 **패킷 전송에 대한 지연을 발생시키고, 송신자의 타임아웃 이벤트에 의한 불필요한 재전송, 이에 따른 링크 용량의 허비라는 비용을 낳는다.**

#### 시나리오 3 : 4개의 송신자와 유한 버퍼를 가지는 라우터, 그리고 멀티홉 경로

![52](https://user-images.githubusercontent.com/31771548/91964473-20b02900-ed4a-11ea-97d5-3ddf37f53b8c.png)

이번에는 좀 더 복잡한 상황이다. 4개의 송신자가 있고, 4개의 라우터를 공유하는 멀티홉 경로이다. 위 그림에서 호스트 A가 호스트 C에게 데이터를 전송하는 Red path와, 호스트 D가 호스트 B에게 데이터를 전송하는 Blue path를 유심히 살펴보자. 이 두 path는 호스트 A와 B 사이에 있는 하나의 라우터를 공유한다(이 라우터를 공유라우터라고 해보자). 그런데 Blue path는 이 공유 라우터에 도달하기까지 하나의 호스트 D와 A 사이에 있는 라우터를 한번 더 거치게 된다(이 라우터를 라우터 B라고 해보자). 그에 따라서 Blue path가 공유 라우터에 전송하는 데이터 전송률은 Host D가 어떤 전송률을 보이고 있든 간에 라우터 B의 링크용량으로 고정되게 된다.

![53](https://user-images.githubusercontent.com/31771548/91964474-20b02900-ed4a-11ea-83ab-2a4711367224.png)

이 같은 구조는 문제가 될 수 있다. 예를 들어서 Host A가 엄청난 속도의 데이터 전송률로 공유 라우터에 패킷을 전달할 경우, 항상 라우터 B의 링크 용량으로 공유라우터에 데이터를 전송하는 Blue path의 패킷들은 공유라우터의 버퍼에 도착하기도 전에 경쟁에서 밀려 손실될 수 있다. 그럼 Host D의 패킷들을 공유라우터까지 전송하는데 사용한 라우터B에서의 노력들은 헛된것이 되어버린다. 이런 문제점은 위 그래프에서 잘 표현된다. 각 호스트에서 아주 작은 데이터 전송률로 데이터를 전송할 때는 연결당 처리량도 그에 따라서 증가하지만 일정 크기 이상을 지나면 연결당 처리량이 0에 수렴하게 된다. 혼잡 네트워크는 **패킷이 경로상에서 버려질 때, 버려지는 지점까지 패킷을 전송하는 데 사용된 상위 라우터에서의 전송 용량은 헛된 것으로 만드는 비용이 발생한다.**

### 3.6.2 혼잡제어에 대한 접근법

혼잡 네트워크가 발생시키는 비용에 대해서 알아보았다. 그럼 이렇게 문제 많은 혼잡 네트워크를 발생시키지 않도록 TCP 동작을 제어하기 위한 두 가지 대표적인 접근법에 대해서 알아보자. 이 두가지는 혼잡 제어를 위해 네트워크 계층의 도움을 받는지에 따라 구분된다.

![54](https://user-images.githubusercontent.com/31771548/91964477-2148bf80-ed4a-11ea-99d0-f6f676e04287.png)

- **종단간 혼잡제어(end-end congestion control)** : 네트워크 계층의 어떠한 지원도 받지 않고 종단에 존재하는 TCP에서 혼잡제어를 수행하는 것이다. 종단의 TCP는 패킷 손실이나 왕복지연시간(RTT)과 같은 증상들로 네트워크 상황을 관찰하고 혼잡제어를 수행한다.
- **네트워크 지원 혼잡제어(network-assisted congestion control)** : 네트워크 계층에서 혼잡에 대한 명확한 피드백을 호스트에게 제공하는 것이다. 호스트에게 네트워크가 혼잡하다는 의미의 패킷을 직접 전송하는 방법과 송신자가 수신자에게 보내는 패킷의 특정 헤더에 네트워크 혼잡에 대한 필드를 채워넣는 방법 등이 존재한다.

## 3.7 TCP 혼잡제어

이제 TCP에서 어떻게 혼잡제어를 수행하는지 알아보자. 먼저 TCP는 네트워크로부터 혼잡에 대한 어떠한 피드백도 받지 않는 **종단간 혼잡제어**를 사용한다. TCP 송신자는 패킷을 송신할 때 확인할 수 있는 여러 증상(패킷 손실, 중복 ack 등)으로 TCP 송신 동작을 제어한다.

TCP의 혼잡제어에 대한 의문점이자 구현목표는 다음과 같은 3가지이다. 1. TCP 송신자는 어떻게 송신률을 조절할 것인가 2. TCP 송신자는 네트워크 혼잡을 어떻게 감지할 것인가 3. 네트워크 혼잡에 따라서 송신률을 조절하는 알고리즘은 어떻게 구성할 것인가

**첫번째로** TCP 송신자는 송신률을 제한하기 위해서 혼잡 윈도우(congestion window, cwnd)라는 변수를 관리한다. 흐름제어에서 살펴보았던 rwnd, LastByteSend, LastByteAcked 변수와 함께 송신속도를 제한하게 된다. 즉, TCP 송신자의 윈도우 사이즈를 다음 수식이 보장되도록 관리한다.  
  
![cwnd](https://user-images.githubusercontent.com/31771548/91979432-bc4c9400-ed60-11ea-819c-de147345d159.png)

우리의 학습을 간단히 하기 위해서 rwnd는 전혀 고려하지 말자. 그럼 TCP 송신자의 최대 데이터 전송률은 cwnd / RTT (바이트/초)로 제한된다.

**두번째로** TCP 송신자는 네트워크의 혼잡 상태를 진단하기 위해서 패킷 손실과 ack, duplicated ack을 사용한다. 송신자가 보낸 세그먼트에 대한 정상적인 ack 신호가 오는 경우 송신자는 네트워크가 혼잡하지 않다고 가정하고 cwnd 크기를 증가시킨다. 만일 수신자로부터 ack신호가 오지 않거나 three duplicated ack 신호가 와서 세그먼트 손실을 확인했다면 네트워크가 혼잡하다는 것을 감지하고 cwnd 크기를 감소시킨다.

**세번째로** TCP 송신자는 네트워크 혼잡 상태에 따라서 적절하게 cwnd크기를 조절하게 된다. 이 cwnd 크기 조절 알고리즘은 **가법적 증가, 승법적 감소(Additive increase, multiplicative decrease)** 기법으로 표현된다.

![55](https://user-images.githubusercontent.com/31771548/91964481-2148bf80-ed4a-11ea-8e9b-9237f04030c8.png)

송신자는 수신자로부터 정상적인 ack 신호를 전달받을 때마다 매 RTT에서 1 MSS 크기만큼 cwnd 사이즈를 증가시킨다(additive increase). 매번 세그먼트들을 전송시키면서 cwnd 사이즈를 선형적으로 증가시킨다. 그러다 패킷 손실을 감지하면 cwnd 사이즈를 절반으로 감소시킨다(multiplicative decrease). 이러한 cwnd 변경은 톱니 모양의 그래프를 그리게한다. 이러한 TCP 송신자의 동작은 어린아이가 부모에게 과자를 조금씩 더 많이 요구하다가 야단을 맞아 과자를 덜 요구하게 되고, 이 후에 다시 과자를 조금씩 더 요구하는 행동과 비슷하다. 이러한 행동의 이유는 **TCP 송신자가 네트워크의 밴드폭을 넘어서서 패킷이 손실되지 않도록 데이터 전송률을 줄이지만, 또한 네트워크의 밴드폭을 최대한 효율적으로 사용할 수 있는 한도 내에서 데이터 전송률을 높이려는 목적**에서 기인한다.

TCP 혼잡제어 알고리즘에 대해서 이제 더 자세히 살펴보자. TCP 혼잡제어 알고리즘은 세가지 주요 구성요소를 갖는다. **(1) 슬로우 스타트(slow start), (2) 혼잡 회피(congestion avoidance), (3) 빠른 회복(fast recovery)**. 이 중 빠른 회복은 권장 사항이지만 필수사항은 아니다.

![56](https://user-images.githubusercontent.com/31771548/91964482-21e15600-ed4a-11ea-9cf6-b6504d50e92c.png)

위 그림은 TCP 송신자의 혼잡제어 방식에 대한 FSM이다. 초기에 TCP 송신자는 cwnd를 1 MSS로 설정하고 ssthresh 를 64KB로 설정한다. 여기서 ssthresh는 slow start threshold의 약자이다. 또한 dupACKcount라는 변수를 0으로 초기화하고 slow start 상태로 진입한다.

### 슬로우 스타트(Slow start)

슬로우 스타트의 이름은 초기 cwnd 사이즈를 1 MSS의 작은 사이즈로 설정한 것에서 유래한 것같다. 그러나 송신자가 보낸 세그먼트에 대해서 정상적인 ACK이 도착했을때의 동작은 이름과는 어울리지 않은 면이 있다. 각 정상적인 ack이 도착할 때마다 슬로우 스타트에서는 cwnd 사이즈를 1 MSS만큼 증가시킨다(여기서는 송신자가 전송한 모든 세그먼트에 대해서 수신자가 ACK을 전송한다고 가정한다). 이에 따라서 송신자는 매 RTT 마다 cwnd 사이즈를 지수적으로 증가시킬 수 있다.

그러나 계속해서 cwnd 사이즈를 지수적으로 증가시키지는 않는다. cwnd 사이즈가 ssthresh와 동일하게 되었을때는 더이상 cwnd 사이즈를 지수적으로 증가시키지 않고 혼잡 회피 상태로 전환하게 된다. 이 때 ssthresh는 말 그대로 슬로우 스타트 상태에서 cwnd 사이즈를 지수적으로 증가시킬 수 있는 임계점이라는 뜻이다.

만일 슬로우 스타트 상태에서 타임아웃이 발생하여 패킷 손실을 감지한 경우 cwnd 사이즈는 다시금 1 MSS로 바뀐다. ssthresh 사이즈는 패킷 손실이 발생한 시점에서의 cwnd 사이즈 절반으로 설정한다. 이 같은 타임아웃 이벤트에 대한 동작은 슬로우 스타트 뿐만 아니라 다른 모든 상태에서도 해당되는 동작이다.

### 혼잡 회피(Congestion avoidance)

앞서 cwnd 사이즈가 ssthresh 와 동일해지면 FSM 상태가 혼잡 회피 상태로 이동하는 것을 살펴보았다. ssthresh는 이전에 패킷손실이 발생한 시점에서 cwnd 사이즈의 절반으로 설정된 값이다. 따라서 cwnd 사이즈가 ssthresh 이상으로 설정된 이 후에는 cwnd 사이즈를 지수적으로 증가시키는 것은 좋지않은 선택이다. 이때부터는 앞으로 발생할지 모를 패킷 손실에 대비해서 cwnd 사이즈를 보수적으로 증가시키게 된다. 혼잡 회피 상태에서는 매 RTT마다 cwnd 사이즈를 1 MSS만큼 증가시킨다. 여러 방식으로 RTT마다 1MSS만큼 추가할 수 있는데, 각 세그먼트의 ack이 도착할 때마다 MSS * (MSS / cwnd)를 cwnd에 더함으로써 구현할 수도 있다.

### 빠른 회복(Fast recovery)

빠른 회복 상태는 송신자가 보낸 세그먼트에 대해서 duplicated ack이 3번 들어오는 경우 진입하게 된다. 이때 ssthresh 사이즈는 duplicated ack을 발생시킨 세그먼트를 전송했던 시점의 cwnd 사이즈 절반으로 설정한다. duplicated ack이 3번 들어와서 패킷 손실을 알리는 상황은 timeout으로 인한 패킷 손실 확인과는 조금 다르다. duplicated ack이 들어왔다는 것은 손실된 세그먼트의 이 후 세그먼트들은 그래도 수신자에게 전송이 되었다는 것이다. 따라서 이같은 상황에서는 cwnd 사이즈를 timeout이 발생했을때처럼 곧바로 1로 설정하는 급진적인 대응보다, 이전 cwnd 값의 절반으로 설정하는 온건적인 대응을 한다. 또한 손실된 세그먼트에 대한 duplicated ack이 들어올때마다 cwnd 사이즈를 1 MSS를 증가시킨다(맨 처음 3 duplicated ack에 대해서도 3MSS를 더해주어서 처리하는듯). 이 후 재전송한 세그먼트에 대해서 정상적인 ack 신호가 들어오는 경우 cwnd 사이즈를 ssthresh 로 설정하고 혼잡 회피 상태로 진입한다.

앞서 빠른 회복 상태는 TCP 혼잡제어를 구성하기 위한 권장사항이지만 필수사항은 아니라고 했다. 실제로 초기 TCP에서는 빠른 회복 상태를 구현하지 않고, duplicated ack이 3번 들어오는 상황에 대해서는 timeout과 동일한 대응을 하여 slow start 상태로 진입하게 한다(TCP Tahoe). 최신의 TCP는 빠른 회복 상태를 구현하여 duplicated ack에 대해서 다른 대응을 한다(TCP Reno).

![57](https://user-images.githubusercontent.com/31771548/91964483-2279ec80-ed4a-11ea-84fd-9dd3edd990de.png)

위 그림은 TCP Tahoe와 TCP Reno의 혼잡제어 동작의 차이점을 보여주는 그림이다. 먼저 8번의 transmission 이전까지는 Tahoe와 Reno가 동일한 동작을 보여준다. 즉, ssthresh 이전까지는 매 transmission마다 cwnd 사이즈를 지수적으로 증가시키고, cwnd가 ssthresh 이상이 될 경우에는 매 transmission마다 1 MSS 만큼 cwnd를 증가시킨다. 차이점을 보이는 것은 8번째 transmission 이후이다. 이 시점에서는 3 duplicated ack이 발생한 시점이다. 양쪽다 ssthresh 값을 cwnd의 절반으로 설정하는 것은 동일하다. 그러나 TCP Tahoe는 cwnd를 1 MSS로 설정하여 슬로우 스타트로 회귀하는 동작을 보이는 반면, TCP Reno는 cwnd 사이즈를 duplicated ack이 발생한 시점의 cwnd 사이즈 절반으로 설정하고 난 뒤 매 transmission마다 1 MSS씩 cwnd를 증가시킨다.
